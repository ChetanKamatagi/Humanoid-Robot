# üöÄ Autonomous Mobile Robot (AMR) 

Welcome to the repository of our groundbreaking **Autonomous Mobile Robot (AMR) Project**. This project is a testament to the synergy of advanced technology and innovative engineering, demonstrating the capabilities of autonomous systems in complex environments.

## üåü Project Overview

Our AMR project integrates cutting-edge components and sophisticated software to achieve autonomous navigation and obstacle avoidance in dynamic environments. 

### Key Components:
- **RPLidar**: For precise environmental mapping.
- **High-Resolution Camera**: For vision-based navigation.
- **Stepper Motors**: For precise wheel control.

### Software Stack:
- **Robot Operating System (ROS)**: Running on the Jetson Nano platform.
- **Arduino**: For motor control and wheel odometry.
- **Simulation Tools**: SolidWorks model transformed into a URDF file, simulated in RViz and Gazebo with ROS.

## üéØ Features

- **Autonomous Navigation**: The AMR autonomously plans routes and avoids obstacles.
- **Precision Mapping**: High accuracy in environmental mapping and localization.
- **Simulation to Reality**: Achieved seamless transition from simulated environments to real-world navigation.

# ü§ñ Maya 3.0 Humanoid Robot Project

<div style="text-align: center">
  <img src="https://github.com/ChetanKamatagi/Humanoid-Robot/blob/main/Team%20Photo" alt="Team Photo" width="500" />
</div>

Welcome to the repository of our innovative **Maya 3.0 Humanoid Robot Project**. This project is an advanced continuation of our Autonomous Mobile Robot (AMR) project, integrating sophisticated features to create a versatile humanoid robot.

## üåü Project Overview

Our humanoid robot, Maya 3.0, builds upon the AMR foundation, adding an upper torso with advanced capabilities such as face tracking, person identification, NLP integration, and more. Maya 3.0 can operate both independently and in conjunction with the AMR base, acting as a master to command the AMR.

### Key Components:
- **Face Tracking**: Follows faces for interaction.
- **Person Identification**: Identifies and recognizes individuals.
- **Person Following**: Follows designated individuals.
- **NLP Integration**: Integrated with ChatGPT for natural language processing.
- **Battery Level Indication**: Monitors and displays battery status.
- **Tour Guide**: Provides guidance and information to visitors.
- **Hand Gestures**: Recognizes and responds to hand gestures.
- **5 DOF Arms**: Equipped with Dynamixel motors and magnetic grippers.
- **1 DOF Neck**: Allows head movements.
- **Face Expressions**: Capable of displaying facial expressions.
- **Control Interface**: User interface to control the robot.
- **Indicator Lights**: Located in the ears and around the AMR for status indication and aesthetic appeal.

### Software Stack:
- **Robot Operating System (ROS)**: Core software framework for communication and control.
- **Jetson Nano**: Computing platform for the AMR.
- **Jetson Xavier**: Primary computing platform for Maya 3.0.
- **Arduino**: Motor control and sensor integration.
- **Simulation Tools**: SolidWorks model transformed into URDF file, simulated in RViz and Gazebo with ROS.

## üéØ Features

- **Autonomous Navigation**: AMR base for precise movement and obstacle avoidance.
- **Advanced Interaction**: Face tracking, person identification, and NLP for dynamic interaction.
- **Gesture Recognition**: Detects and responds to hand gestures.
- **Tour Guide Capability**: Engages with visitors, providing tours and information.
- **Versatile Movement**: 5 DOF arms with Dynamixel motors and magnetic grippers for object manipulation.
- **Depth Perception**: 3D cameras for capturing depth information of the environment and individuals.


## üíª Technical Details

### Hardware

- **RPLidar**
- **High-Resolution Camera**
- **Stepper Motors**
- **Jetson Nano**
- **Arduino**
- **RPLidar**: For precise environmental mapping.
- **High-Resolution Camera**: For vision-based navigation and face tracking.
- **3D Cameras**: For capturing depth information.
- **Stepper Motors**: For precise wheel and joint control.
- **Jetson Nano**: Computing platform for the AMR.
- **Jetson Xavier**: Primary computing platform for Maya 3.0.
- **Arduino**: Microcontroller for motor control and sensor integration.
- **Dynamixel Motors**: For arm movements.
- **Magnetic Grippers**: For object manipulation.
- **Batteries**: Power supply with level indication.
- **Indicator Lights**: For status indication and aesthetic appeal.


### Software
- **ROS**: Core operating system for robot control and navigation.
- **Gazebo & RViz**: Simulation tools for environment testing.
- **SolidWorks**: Used for 3D modeling of the robot.


## üì∑ Gallery

![AMR Design](path_to_your_image_1.jpg)
![Simulation Environment](path_to_your_image_2.jpg)
![Real-World Testing](path_to_your_image_3.jpg)

## üìö Documentation

Detailed documentation for setting up and running the AMR project can be found in the [Documentation](docs/documentation.md) section.

- **ChatGPT**: NLP integration for interactive communication.


## üì∑ Gallery

### Design Images

<div style="text-align: center;">
  <img src="https://github.com/ChetanKamatagi/Humanoid-Robot/blob/main/Design%20of%20MAYA.png" alt="Humanoid Design" width="500" height = "600"/>
  <img src="https://github.com/ChetanKamatagi/Humanoid-Robot/blob/main/Design%20of%20MAYA%202.png" alt="Humanoid Design 2" width="500" height = "500"/>
</div>


## MAYA in Motion: YouTube Video Gallery

Explore our full playlist of videos:
[Link to YouTube Playlist](https://www.youtube.com/playlist?list=PLeK5bZUD6DaQ4cjS5HvWraS2Y5s2-53HB)

## üé• Concept Video

Check out our [YouTube video](https://www.youtube.com/watch?v=97EMlYxOZNI) showcasing Maya 3.0 serving as a nursing robot, assisting patients and providing care as part of our vision for robotic healthcare solutions.


## üìö Documentation

Detailed documentation for setting up and running the Maya 3.0 humanoid robot project can be found in the [Documentation](Detailed_Report.pdf) section.

## ü§ù Acknowledgements

This project would not have been possible without the unwavering support of numerous individuals and institutions. Special thanks to everyone who contributed to the success of this endeavor.


